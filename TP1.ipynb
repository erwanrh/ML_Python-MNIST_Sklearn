{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> TP1 : Basic functions for Supervised Machine Learning. </center></h1>\n",
    "\n",
    "The deadline for report submission is Tuesday, November 10th 2020.\n",
    "\n",
    "Note: the goal of this first TP is to become familiar with 'sklearn' class in Python. In particular, we introduce most popular supervised learning algorithms. \n",
    "\n",
    "PART 1 is a list of commands that should be followed step by step. PART 2 is an open problem for which we are waiting for your creativity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler\n",
    "from sklearn.metrics import balanced_accuracy_score, make_scorer, confusion_matrix\n",
    "\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imported packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  PART 1 -- MNIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part of TP1 we pursue the following goals:\n",
    "1. Apply standard ML algorithms on a standard benchmark data\n",
    "2. Learn basic means of data visualizations\n",
    "3. Get familiar with sklearn's GridSearchCV and Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST dataset consists of black and white images of hand-written digits from $0$ to $9$ of size $28 \\times 28$.\n",
    "In this exercise we will work with a small from the original MNIST dataset. \n",
    "\n",
    "If you are interested in the whole dataset, execute the following commands\n",
    "```python\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original', data_home=custom_data_home)\n",
    "```\n",
    "\n",
    "Hence, the observations $(X_1, Y_1), \\ldots, (X_n, Y_n)$ are such that $X_i \\in \\mathbb{R}^{784}$ and $Y_i \\in \\{0, \\ldots, 9\\}$. To be more precise, each component of vector $X_i$ is a number between $0$ and $255$, which signifies the intensity of black color.\n",
    "\n",
    "The initial goal is to build a classifier $\\hat g$, which receives a new image $X$ and outputs the number that is present on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data contains: 2000 samples of dimension 784\n",
      "Test data contains: 200 samples\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load('data/mnist1_features_train.npy', allow_pickle=True)\n",
    "y_train = np.load('data/mnist1_labels_train.npy', allow_pickle=True)\n",
    "X_test = np.load('data/mnist1_features_test.npy', allow_pickle=True)\n",
    "y_test = np.load('data/mnist1_labels_test.npy', allow_pickle=True)\n",
    "\n",
    "n_samples, n_features = X_train.shape # extract dimensions of the design matrix\n",
    "print('Train data contains: {} samples of dimension {}'.format(n_samples, n_features))\n",
    "print('Test data contains: {} samples'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each observation is actually an image, we can visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "axes = plt.subplots(1, 10)[1]  # creates a grid of 10 plots\n",
    "\n",
    "# More details about zip() function here https://docs.python.org/3.3/library/functions.html#zip\n",
    "images_and_labels = list(zip(X_train, y_train)) \n",
    "for ax, (image, label) in zip(axes, images_and_labels[:10]):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image.reshape((28, 28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title('{}'.format(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0s in the train dataset is 196\n",
      "Number of 1s in the train dataset is 226\n",
      "Number of 2s in the train dataset is 214\n",
      "Number of 3s in the train dataset is 211\n",
      "Number of 4s in the train dataset is 187\n",
      "Number of 5s in the train dataset is 179\n",
      "Number of 6s in the train dataset is 175\n",
      "Number of 7s in the train dataset is 225\n",
      "Number of 8s in the train dataset is 186\n",
      "Number of 9s in the train dataset is 201\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('Number of {}s in the train dataset is {}'.format(i, np.sum([y_train == str(i)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we conclude that the dataset is rather balanced, that is, each class contains similar amount of observations. The rarest class is $y = 6$ with $175$ examples and the most common class is $y = 2$ with $226$ examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question:** Explain in your report what happens when we run \n",
    "```python\n",
    "clf.fit(X_train, y_train)\n",
    "```\n",
    "What is the complexity for each of the three following cases? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned hyperparameter: {'n_neighbors': 1}\n",
      "Best classification accuracy in train is: 0.891497944721333\n",
      "Classification accuracy on test is: 0.875\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV with kNN : a simple baseline\n",
    "knn = KNeighborsClassifier() # defining classifier\n",
    "parameters = {'n_neighbors': [1, 2, 3, 4, 5]} # defining parameter space\n",
    "clf = GridSearchCV(knn, parameters, cv=3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('Returned hyperparameter: {}'.format(clf.best_params_))\n",
    "print('Best classification accuracy in train is: {}'.format(clf.best_score_))\n",
    "print('Classification accuracy on test is: {}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is the test accuracy? What would be the accuracy of random guess?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question:** What is ``` LinearSVC()``` classifier? Which kernel are we using? What is ```C```? (this is a tricky question, try to find the answer online)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is the outcome of ```np.logspace(-8, 8, 17, base=2)```? More generally, what is the ourcome of ```np.logspace(-a, b, k, base=m)```?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVM Classifier\n",
    "svc = LinearSVC(max_iter=5000)\n",
    "parameters2 = {'C': np.logspace(-8, 8, 17, base=2)} # defining parameter space\n",
    "clf2 = GridSearchCV(svc, parameters2, cv=3)\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Returned hyperparameter: {}'.format(clf2.best_params_))\n",
    "print('Best classification accuracy in train is: {}'.format(clf2.best_score_))\n",
    "print('Classification accuracy on test is: {}'.format(clf2.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What is the meaning of the warnings? What is the parameter responsible for its appearence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVM Classifier + Pipeline\n",
    "pipe = Pipeline([('scaler', MaxAbsScaler()), ('svc', svc)])\n",
    "parameters3 = {'svc__C': np.logspace(-8, 8, 17, base=2)} # defining parameter space\n",
    "clf3 = GridSearchCV(pipe, parameters3, cv=3)\n",
    "clf3.fit(X_train, y_train)\n",
    "\n",
    "print('Returned hyperparameter: {}'.format(clf3.best_params_))\n",
    "print('Best classification accuracy in train is: {}'.format(clf3.best_score_))\n",
    "print('Classification accuracy on test is: {}'.format(clf3.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What did we change with respect to the previous run of ```LinearSVC()```?\n",
    "\n",
    "**Question:** Explain what happens if we execute\n",
    "```python\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pipe.predict(X_test, y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('logreg', LogisticRegression(max_iter=5000))])\n",
    "parameters4 = {'logreg__C': np.logspace(-8, 8, 17, base=2)} # defining parameter space\n",
    "clf4 = GridSearchCV(pipe, parameters4, cv=3)\n",
    "clf4.fit(X_train, y_train)\n",
    "\n",
    "print('Returned hyperparameter: {}'.format(clf4.best_params_))\n",
    "print('Best classification accuracy in train is: {}'.format(clf4.best_score_))\n",
    "print('Classification accuracy on test is: {}'.format(clf4.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** what is the difference between ```StandardScaler()``` and ```MaxAbsScaler()```? What are other scaling options available in ```sklearn```?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** using the previous code as an example achieve test accuracy $\\geq 0.9$. You can use any method from sklearn package. Give a mathematical description of the selected method. Explain the range of considered hyperparamers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some ```sklearn``` methods are able to output probabilities ```predict_proba(X_test)```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** There is a mistake in the following chunk of code. Fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "axes = plt.subplots(2, 4)[1]  # creates a grid of 10 plots\n",
    "\n",
    "# More details about zip() function here https://docs.python.org/3.3/library/functions.html#zip\n",
    "y_pred = clf4.predict(X_test)\n",
    "j = 0 # Index which iterates over plots\n",
    "for true_label, pred_label, image in list(zip(y_test, y_pred, X_test)):\n",
    "    if j == 4: # We only want to look at 4 first mistakes\n",
    "        break\n",
    "    if true_label != pred_label:\n",
    "        # Plotting predicted probabilities\n",
    "        axes[1, j].bar(np.arange(10), clf4.predict_proba(image.reshape(1, -1))) \n",
    "        axes[1, j].set_xticks(np.arange(10))\n",
    "        axes[1, j].set_yticks([])\n",
    "        \n",
    "        # Plotting the image\n",
    "        axes[0, j].imshow(image.reshape((28, 28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        axes[0, j].set_xticks([])\n",
    "        axes[0, j].set_yticks([])\n",
    "        axes[0, j].set_title('Predicted {}'.format(pred_label))\n",
    "        j += 1\n",
    "        \n",
    "#         plt.xticks(x, ('Bill', 'Fred', 'Mary', 'Sue'))\n",
    "#         axex[1, j].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing the Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It often happens that the accuracy is not the right way to evaluate the performance. ```sklearn``` has a large variety of other metrics both in classification and regression. See https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "\n",
    "Here we want to understand how to change the cross-validation metric with minimal effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVM Classifier + Pipeline + New score function\n",
    "\n",
    "pipe = Pipeline([('scaler', MaxAbsScaler()), ('svc', svc)])\n",
    "parameters4 = {'svc__C': np.logspace(-8, 8, 17, base=2)} # defining parameter space\n",
    "balanced_scorer = make_scorer(balanced_accuracy_score)\n",
    "\n",
    "clf4 = GridSearchCV(pipe, parameters3, cv=3, scoring=balanced_scorer)\n",
    "clf4.fit(X_train, y_train)\n",
    "\n",
    "print('Returned hyperparameter: {}'.format(clf4.best_params_))\n",
    "print('Best Balanced accuracy in train is: {}'.format(clf4.best_score_))\n",
    "print('Balanced accuracy on test is: {}'.format(clf4.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is ```balanced_accuracy_score```? Write its mathematical mathematical description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Sometimes it is important to look at the confusion matrix of the prediction.\n",
    "\n",
    "**Question:** What is the confusion matrix? What are the conclusions that we can draw from the ```confusion_matrix(y_test, clf4.predict(X_test))```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, clf4.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2 -- Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that we have contains images with $10$ classes. Normally, accuracy is a reasonable choice of the loss function to be optimized, but in this problem we *really* do not like when digits from $\\{5, 6, 7, 8, 9\\}$ are predicted to be from $\\{0, 1, 2, 3, 4\\}$.\n",
    "\n",
    "**Question:** Propose a loss function that would address our needs. Explain your choice.\n",
    "\n",
    "**Question:** Following above examples, make an ML pipeline that uses *your* loss function and finds appropriate classifiers.\n",
    "\n",
    "When writing your report on this part, include:\n",
    "   1. description of your loss function\n",
    "   2. description of the pipeline\n",
    "   3. description of the algorithms that you used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

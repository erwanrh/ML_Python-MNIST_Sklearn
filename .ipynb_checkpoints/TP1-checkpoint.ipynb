{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> TP1 : Basic functions for Supervised Machine Learning. </center></h1>\n",
    "\n",
    "The deadline for report submission is Tuesday, November 10th 2020.\n",
    "\n",
    "Note: the goal of this first TP is to become familiar with 'sklearn' class in Python. In particular, we introduce most popular supervised learning algorithms. \n",
    "\n",
    "PART 1 is a list of commands that should be followed step by step. PART 2 is an open problem for which we are waiting for your creativity!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imported packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler\n",
    "from sklearn.metrics import balanced_accuracy_score, make_scorer, confusion_matrix\n",
    "\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  PART 1 -- MNIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part of TP1 we pursue the following goals:\n",
    "1. Apply standard ML algorithms on a standard benchmark data\n",
    "2. Learn basic means of data visualizations\n",
    "3. Get familiar with sklearn's GridSearchCV and Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST dataset consists of black and white images of hand-written digits from $0$ to $9$ of size $28 \\times 28$.\n",
    "In this exercise we will work with a small from the original MNIST dataset. \n",
    "\n",
    "If you are interested in the whole dataset, execute the following commands\n",
    "```python\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original', data_home=custom_data_home)\n",
    "```\n",
    "\n",
    "Hence, the observations $(X_1, Y_1), \\ldots, (X_n, Y_n)$ are such that $X_i \\in \\mathbb{R}^{784}$ and $Y_i \\in \\{0, \\ldots, 9\\}$. To be more precise, each component of vector $X_i$ is a number between $0$ and $255$, which signifies the intensity of black color.\n",
    "\n",
    "The initial goal is to build a classifier $\\hat g$, which receives a new image $X$ and outputs the number that is present on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data contains: 2000 samples of dimension 784\n",
      "Test data contains: 200 samples\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load('data/mnist1_features_train.npy', allow_pickle=True)\n",
    "y_train = np.load('data/mnist1_labels_train.npy', allow_pickle=True)\n",
    "X_test = np.load('data/mnist1_features_test.npy', allow_pickle=True)\n",
    "y_test = np.load('data/mnist1_labels_test.npy', allow_pickle=True)\n",
    "\n",
    "n_samples, n_features = X_train.shape # extract dimensions of the design matrix\n",
    "print('Train data contains: {} samples of dimension {}'.format(n_samples, n_features))\n",
    "print('Test data contains: {} samples'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each observation is actually an image, we can visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABLCAYAAABgOHyfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAF5FJREFUeJztnXtUVNehxr89ERzLm/C8CBIjQpaPqDEaL8RHl5iSiFaXjeGmolirshLSCytaqSToZaGkljRCYzW2akKWNaJG6lXjMj5arsZHgkZ6IwGDJIhRAkVAAV989w+YcxkZ4Mx7nO7fWnuJzJxzfuxzzjf77LPPHkESEolEInn40dhbQCKRSCSWQQa6RCKROAky0CUSicRJkIEukUgkToIMdIlEInESZKBLJBKJkyADXSKRSJwEhw50IUS4EOKAEKJBCHFNCPEHIUQ/O3h8KIT4XgjRJIQoF0IssrVDF5eXhBAXhRC3hBDfCCGetYODQ9SHEOLmA+W+ECJfetjXo9PFUY6R40KIti518rUdHGy3X0g6bAFwAMA2AFoAQQBKAbxmB49hAPp3/hwF4BqAp+zgEQvgWwDPoOPDOARAyL9qfTzg5AbgJoCJ0sP+Ho5yjAA4DmCRPfeFLfeLQ7fQATwGYCfJNpLXAHyCjgPFppD8X5K3df/tLI/b2gPAagD/RfIUyXaSNSRrbC3hQPXRlTkAagEUSw/7ezjoMeIIWHW/OHqgrwfwkhDiR0KIEABx6Ah1myOE2CCEaAFQBuB7dFw92HL7jwAYC8BfCHFJCHGlswtqgC09uvjYtT4MMB/AB+xsBkkP+3s40DGyVghRJ4Q4IYSYbCcHHdbdL/a+BOnj8uQJAF8AuIeOT/htAIQdfR4BEAMgA4CLjbf9b5118DmAYAB+AE4AyP5XrI8HPMIA3AfwmL0cpIdjHiMAxgPwANAfHWHaDOBxZ90vDttCF0JoABwCsAcd/U5+AHwAvGUvJ5L3Sf4PgIEAkm28+dbOf/NJfk+yDsDbAJ63sYeCneujK4kA/ofkZTs6SA8D2PsYIXmaZDPJ2yTfR0cjyF7njNX3i8MGOgBfAKEA/tC5M+oBbIUdA6wL/WDj/kCSDQCuoKOV7mjYvD4eIBHA+3bcvg7p0TP2PkZ0EICw07atvl8cNtA7W6CXASQLIfoJIbzRccn0pS09hBABnUMF3YUQjwghngOQAOCoLT062QogpdPJB8B/AvhvWwo4WH1ACPHv6BjtU2iP7UsPgw4OcYwIIbyFEM8JIbSdGfIygInouPK3KbbaL6Kzb8chEUKMAvAOgCfR0fd0DMArJGtt6OAPYFengwYdwwbzSG62lUMXFxd03Cj+DwBtAHYCWE6yzYYODlMfnT6bAPyI5Dx7bF96GHRwiGOk0+MAOoZN3kfHzdk3SB62pUeni032i0MHukQikUjU47BdLhKJRCIxDhnoEolE4iTIQJdIJBInQQa6RCKROAm2nrnQHndgDY05lR76SA99pIc+0kMfR/HohmyhSyQSiZMgA10ikUicBBnoDzElJSV49NFHIYTAvn377K0jkUjsjK0fLHKUvqeH2qO1tWOerokTJ+KLL74AAHh4eKCxsdGmHmYiPfSRHvqY5VFXVwcA8PPzQ3V1NQCgvr4eAFBUVITs7GxMnToV+fn5ePzxXqeYceT66IbNv87NGNrb21FVVaX3u8GDBys//+Y3v8HatWuxZ88ezJgxA4888ohFt9/a2opDhw5h9erVOH/+fLfXt2zZAh8fHwDAkCFDMHz4cItuvyd0Ia77FwCCgoJssm0JsHfvXuTk5OD06dPK7yIiIrBoUce3rHl4eCA52TYTC164cAGrVq0CAPzqV7/C2LFj4ebmZpNtt7e3o7KyEllZWTh58iTmzp2r9/rEiRMBABMmTIBWq4WLi4tNvAAgPj4e169fR2BgICorKwEAtbX6M4YcPHgQH3zwAVavXm0zL2vjkC30xsZGLF++HDU1NThwQH9O/Ly8PLz66quoqalBbGwsysrKAACbN2/GL37xC0OrU/0J+/XXX+Ott/5/dt6Wlhbs3LlTjTKGDx+OXbt2YejQoT29xWKf9CkpKQCAd999FwAwaNAgHDlyRO/DrhfM8rh37x7Kysrwj3/8A1euXAEANDU1obCwEGVlZfDz88ORI0cwcuRIq3roqKqqwrFjxwAAOTk5KC8v13t99uzZ+PDDDzFgQI/fA2KUx3fffYfY2Nhu2+mKRqPBggULEBMTg5///Odqg8yk+ti0aROSk5ORmJgIV1dXHD58GKNHjwYAuLi4YNKkSQCAgQMHYtKkSfDy8rKYx4YNG5Rj0RC6bBFCYOrUqZg0aRKWLFmCRx99tC8Hozy6Ul9fj5ycHOTm5sJQtoWFhaGhoQFDhgxBRkYG4uPj+9o/Jh+nmzZtQm1tLRYsWIDjx4/j5MmTAICNGzcCALy9vZGWlobnn38eTz31VF+rUzdDpI0nee+TM2fOMC4ujkIIg8XV1ZXHjh3j5s2b9X6/ffv2nlap2iM0NLTH7aopnp6eTElJMdujN/bt20dvb296e3sr201NTTVmFUZ7tLe3s7S0lJmZmfT19aUQggEBAZw3bx7nzZvHV199lXv27OGMGTOo0Wj417/+1Soed+/e5Q8//MC0tDRGRUUxKiqKfn5+9PHxoY+PD2fNmsUVK1bw8OHDzMzMZGhoKAEwOzvboh7V1dW8ePFij+XUqVMMDw8nAM6fP59nz561Sn3o8PPz43vvvaf8/8qVK7xy5QpPnjzJzMxMLl++nPHx8QwMDOTOnTst4tHQ0MDIyEhqNBqGhoYyLi6OW7du5datWzl69GhGRkZyyJAhHDJkCDUajVKCg4N56tQpNX+WSfXx8ssv677ujv7+/ly1ahU//fRTpTQ1NbG0tFTNqkz2KC0tZWJiIjUajZJZup8NFS8vL37++eemeHT/Eg21b7RQ6ZPU1FQKIajVavnGG2/w9OnTvHXrFm/dusXi4mJmZ2dz1KhR1Gq1SoUkJyfz5s2bxlSEQV5//XW9ivb29ubbb7/NqKgo1aE+YsSIng4YiwT6/Pnzu22zoKDAmFUY5dHS0sL09HQlxF955RUePXpU7z1tbW1MTU1lcHAwt23bZhUPkrx48SKFEARAIQTnzp3LoqIi1tfXs76+vtv7Y2JiCICHDx+2qIcafve73ynBMmXKFDY3N/e1iFmBPm3atF7fs2HDBgLgk08+aRGP1tZW/vjHP6a7uztPnDhhcEV3797l3bt3WVhYyKSkJPr6+lKj0TAkJISXL1+2iEdXSktLOWDAAOX4ePPNN/taRA2qPZKSkujp6amXTV1LUFAQg4KCmJqaytTUVC5cuFB5bf369aZ4OH6gu7u7UwjBhISEHt8zY8YMpSImTpzIuro6YyvCIGVlZfzmm2+U8u2335Ikq6qq+Morryi/HzNmDP38/AzuNF9fXx47dswsj56oqamhq6ur3vY2bNjA9vZ2Y1aj2qO8vJyxsbH09fVlbm5ut9erq6tZXV3N+Ph4xsTEWL3lU19fz9/+9rdKqaio6PG95eXl7N+/P1NSUnjv3j2LeqjhvffeUwIdAE+fPt3XIiZ7LF68mK6urr2+52c/+xkBcMaMGRbzWLt2LRctWqRWk7t27VJa6ufOnbOYh46FCxcq9d01Py5cuMALFy4wNzeX8+fP5/79+3nnzh212qo8/vjHP+q1wiMiIpicnMzk5GSeO3eOdXV1vHHjBm/cuKEsU1lZ+a8T6NHR0Wxtbe32+tGjR+nj46OEZx9h3lNFGERtS/fSpUt85plnuoW5m5sb9+zZY7aHIdrb27lkyRK97Wm1WpaXlxuzGtUeLS0tjI2N5cyZM7vV8b1797h//34GBgYyMDCQa9as4a1bt6ziYSq6uiouLraLx2uvvaYX6MuXL7eqR2/nwbVr16jVagmAH3zwgVU9eqOkpMRqgV5WVqb8jQA4efJkrlmzhgkJCXR3d6e7u7ve/ggNDWVycrLF8iM+Pp7z5s3ju+++y9dff13VeVlYWKicx31cRfbk4fiBrutyEUKwpqZG77U7d+5wwIABSr+Utfpqu3Lz5k1WVlby6aefVkpkZKTB/vNe+vHN9rh9+3a3bSYlJRmzCqM8zp49y+jo6G4HfHNzM5cvX87g4GDu37+f+/fvN8VBtYex3Llzhzk5OQTAOXPm2MXjxo0bHDdunF6ArFmzxuYeOvbu3UsA9PPz4/379+3icebMGc6aNctqXS4jR47Uq2+1RcUVhiqPxsbGvq4E9bh06RI9PDwohKC/v7+aRR7OQP/b3/6m3PAbN26cXt/oG2+8ofSPpaenq1ldTxWhips3b/Kll17qs9/c29ubu3fvtprH1atXuXbtWmV7w4YN47Bhw5S6OXXqFIuLi3nmzBk1qzPZ48SJExw7dizj4uJYVVWldjGLe/TG0aNHKYTgwIED1TpazKO2tpa1tbVcvXp1t+BQ0Z9rlfq4evUqH3vsMQLg7Nmz1SxiEY/z589z48aN3LhxI4cOHUpvb2/lpqiK7iejPXR957qi1Wr5xBNP0NXVVSkJCQksLi7mp59+yq+++oqTJk1iv379uG7dut66La2yX3StcyEEp0yZomaRhzPQSXLlypXKH5uSksKioiIWFRUpOy0gIMCYQDHZ48qVK6puhG7dutWqHvn5+Xrb0wV6bm4u09LS2L9/f3Mv3Xrl3r17fPPNN+nj48P09HR+9tlnfOutt5QydepUjh8/nuPHj+fixYuV3+tGFVi6Pnqirq6O0dHRFEKwpKRE7WIW8ygpKWFJSUm3MH/hhRd4+/Ztm3l0JS8vjwAYFRWlpnvBKI+Ghgbm5eXplUWLFjE4OJheXl7K8arrZpk+fbraET9GeZD6ge7l5dXtxr0hdFcuALh582aLeKhh7969SqN18uTJ5uyXhyPQW1tbmZSUpNcC1lUAAKuO6uhKfX09x40b12egBwUFqQkQkz2WLl2qepTN1KlTLepx//595ufnEwBdXV0ZGhpKX19fRkZGKiUlJYUrV65USlxcHCMjIzlw4ECGh4fzk08+MdQCstiJ0tDQwIaGBq5atYouLi5ct26dmq4Fi3qcPHmS06dP5/Tp07sFusqrSYsHR2lpKV1dXQnA4E1tcz2WLl2qNyTxwdI10Ddu3Mi7d+8ao29UfXzxxRfMzMzktGnTVN9XSkxMVPZRXFycRTzUMHPmTKVutmzZonYxVRkr53KRSCQSZ0Ft8luoGEVAQIBeS8fLy8uYS+nePtlUU1FRwR07dugVXRdH17Js2TKreYSFhaluof/pT3+ymMeXX37JBQsWEAB9fX05c+ZMFhQU8OrVq6q8m5qa+Oc//5kuLi48cOCAyR59sWLFCq5YsYIATLlRbLZHaWkpIyMjDd50W7JkCVtaWmzioaOlpYUtLS2cPXu2Mg7eiKGtqj2Sk5O7DaPtWnR1oBuRtn79ejY1Nam9eWhSfai9Mrt9+zafffZZxTEtLc2iHoZobGxkY2Oj0i0YEhLC69evq11cVcY6bKAXFBR0G6Cv8qaOmoowi7a2tm5DCF1cXPoaImeSx1/+8hfVYe7t7a1mLLhqj4KCAgYGBhoV4g+yZ88euri48MKFCyZ79MbmzZuVkzI6OtqUVZjlsWPHjm435HTF09NTzQNFFvHoSn5+vtJN5u3trfbJTJM8Dhw4oGzvwZKbm8vc3FyGhITQ3d1d6YpZsWKFmnHgFj9vu5KSkqK3r/7+979b3KOuro7FxcVKSUhIYEJCgnK+DhgwgHl5efz+++/VrO7hDfTr169z8ODBBkPLBKxyYHQdjaMr1gj07du3qw70QYMGqVmlao/GxkZeu3ZNzToNsnv3bo4cOZIvvviiVfrQy8vLGRISwlGjRnHUqFFqbggbwiSP9vZ27t27lxqNxmCYa7VafvbZZ1b3eJCzZ8+yX79+7NevHwFw3bp1xq7CKudLcXExc3JyOGjQIGo0Gqanp/d1o9gqHrdv3+4W5lOmTOntqsFoj7q6Om7ZsoVjxozp85wdNWoUv/vuOzXqD2egNzc3Mzs7W/mD3dzcjAlNtRVhNpcvX2ZAQIDilZycbJUDVG2ga7VaFhUVqVmlVerjQSorKxkUFMSYmBi9p+Ms6ZGSkkIvLy8eOnSIhw4dMlXVJI/GxsZexzfn5eXZxONBp8DAQMVhwoQJxj5FbBGP3igpKaGnpyc1Gk1fHzYmebS0tPTY4q2qqlKuXHQlMjKSO3bssKhH1wEdPZXw8HBmZWUpT6Or4OEM9K6VER4ezuLiYoaFhSn9yO+8847aCuitIsyivLycY8eOtUkf+qxZs1QF+urVq9XqWz3Qd+/eTT8/v97C3GyPrKwsarVaU4LTbI/t27fTw8OjW4j7+/vT39+fv/71r9UMUzTboyv3799nbGwsASiTYhnR3WMxDzW8/PLL1Gg0DAsL4z//+U+LeTQ0NHDt2rX85JNPlN/V19fzo48+4kcffcSf/vSn3fZZHxO3meRRVVXFpUuXsrCwUCkjRozQO18LCwv7Wo0aD8cP9K4T1rz//vvMyMjQqwgDN9dMqQg9jhw5wuHDhyuluLiYFRUVrKioYG1tLWtqalhRUcGlS5dy6dKlDA8Pt9lN0blz56oKc2vc9DKF7Oxsuru7MyUlpbcwN8tj165ddHNz4y9/+Utj5uSwmMesWbMMtsoTExOZmJhoM4+u7NixgwAYFBTEc+fOqXm03ioeasjPz1f603vp0lPtUVNTw127djEgIIAxMTH84YcfuG/fPs6ePZuenp4G91VERATffvttNTesza6PlpYWTpgwQa+bxYiWeW8ejh/o/v7+FEJw+PDhrKmp4dNPP231PvSPP/64x7CMiYnpc7bFpKQkNdMQmFQfTU1NvU4n/OKLL7KxsdGi9WEKFRUVnDZtGn19fZmTk2PVR8x1Nxy//fZbs/r4TfEoLS2lj4+PXjgEBgby448/7jb5kjU9ulJdXc3+/ftTo9EYM9ulRT2uXr3KuLg4btq0yeAcTGfOnOHOnTs5Z84cpctl8ODBbGhoMNtj27Ztyr7o168fg4ODe+wK8/X1ZVpamjHHjdnny969e/XOWZVdo2o8HD/QdZNzDRkyRJm3RVd6m4HRyIrQo7dA7634+PjQz8+PFy9etIhHT7S1tXHfvn1MSUmhv7+/MkxvxYoVxgx7MtvjQZqbm9nc3MzMzExqtVpGRUUZc4/DaI+7d+9y5cqVyqP0v//97025p2KWx+LFi7sFxPHjx811MNpDR2NjI0NCQgiAM2fOtJvHgQMHlFb34MGDOXToUEZERDAiIkLv0f+u7ykrK7OIx6VLlxgWFtZjiOu6oCZMmMCsrCy19WC0hyEaGho4fvx4CiGUKQgOHjxorENPHo4f6ImJid2CMzo6mtHR0WrH86qpCD1KSkq4cOHCHucxfrAsWLCACxcu7K11YZKHjTDb49atW1y0aBHd3Nzo5ubGqKgoFhQUGNtvbLRH1/nQtVqtKf2QZnvExcUpQeHu7s6TJ09awsFoDx1PPvkkAVCj0aiZ8MpqHm1tbUxKSurxSVFdCQ0N5fr169WcO0Z5fPXVV5w4cSKTk5P5wgsvEACDg4N5/PjxHufLV4nJ58udO3c4evRoCtExrDkrK8uUD5TePBw/0Hfu3KkcCK6urszKyuK1a9fMubRW7bFu3boe+6h188kUFRUZNauaKR5WxmiPgwcPctiwYSwoKGBFRQWfe+45enh4MD09nenp6aaeLEZ76Lqe3Nzc1HzzjlU8ampqOGLECM6ePduSYW60h445c+YQgDmjfCziQXZcQZ04cYIZGRnMyMjgsmXLuGzZMv7kJz9hRkYGP//8c2MaZQ/t+aKja1fLs88+aw0Pxw90KyA9zPRob2/nkSNHlBbYmDFjeP78eZt7ZGdnMyoqytBDSjb1sBLSw8k87BHoDvkl0RbGYl/ObCbSQx/poY/00Ed66KPqS6Ll5FwSiUTiJNi6hS6RSCQSKyFb6BKJROIkyECXSCQSJ0EGukQikTgJMtAlEonESZCBLpFIJE6CDHSJRCJxEmSgSyQSiZMgA10ikUicBBnoEolE4iTIQJdIJBInQQa6RCKROAky0CUSicRJkIEukUgkToIMdIlEInESZKBLJBKJkyADXSKRSJwEGegSiUTiJMhAl0gkEidBBrpEIpE4CTLQJRKJxEmQgS6RSCROggx0iUQicRJkoEskEomT8H8rvf2KNdyaxQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "axes = plt.subplots(1, 10)[1]  # creates a grid of 10 plots\n",
    "\n",
    "# More details about zip() function here https://docs.python.org/3.3/library/functions.html#zip\n",
    "images_and_labels = list(zip(X_train, y_train)) \n",
    "for ax, (image, label) in zip(axes, images_and_labels[:10]):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image.reshape((28, 28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title('{}'.format(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print('Number of {}s in the train dataset is {}'.format(i, np.sum([y_train == str(i)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we conclude that the dataset is rather balanced, that is, each class contains similar amount of observations. The rarest class is $y = 6$ with $175$ examples and the most common class is $y = 2$ with $226$ examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question:** Explain in your report what happens when we run \n",
    "```python\n",
    "clf.fit(X_train, y_train)\n",
    "```\n",
    "What is the complexity for each of the three following cases? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GridSearchCV with kNN : a simple baseline\n",
    "knn = KNeighborsClassifier() # defining classifier\n",
    "parameters = {'n_neighbors': [1, 2, 3, 4, 5]} # defining parameter space\n",
    "clf = GridSearchCV(knn, parameters, cv=3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('Returned hyperparameter: {}'.format(clf.best_params_))\n",
    "print('Best classification accuracy in train is: {}'.format(clf.best_score_))\n",
    "print('Classification accuracy on test is: {}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is the test accuracy? What would be the accuracy of random guess?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question:** What is ``` LinearSVC()``` classifier? Which kernel are we using? What is ```C```? (this is a tricky question, try to find the answer online)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is the outcome of ```np.logspace(-8, 8, 17, base=2)```? More generally, what is the ourcome of ```np.logspace(-a, b, k, base=m)```?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVM Classifier\n",
    "svc = LinearSVC(max_iter=5000)\n",
    "parameters2 = {'C': np.logspace(-8, 8, 17, base=2)} # defining parameter space\n",
    "clf2 = GridSearchCV(svc, parameters2, cv=3)\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Returned hyperparameter: {}'.format(clf2.best_params_))\n",
    "print('Best classification accuracy in train is: {}'.format(clf2.best_score_))\n",
    "print('Classification accuracy on test is: {}'.format(clf2.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What is the meaning of the warnings? What is the parameter responsible for its appearence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVM Classifier + Pipeline\n",
    "pipe = Pipeline([('scaler', MaxAbsScaler()), ('svc', svc)])\n",
    "parameters3 = {'svc__C': np.logspace(-8, 8, 17, base=2)} # defining parameter space\n",
    "clf3 = GridSearchCV(pipe, parameters3, cv=3)\n",
    "clf3.fit(X_train, y_train)\n",
    "\n",
    "print('Returned hyperparameter: {}'.format(clf3.best_params_))\n",
    "print('Best classification accuracy in train is: {}'.format(clf3.best_score_))\n",
    "print('Classification accuracy on test is: {}'.format(clf3.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What did we change with respect to the previous run of ```LinearSVC()```?\n",
    "\n",
    "**Question:** Explain what happens if we execute\n",
    "```python\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pipe.predict(X_test, y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('logreg', LogisticRegression(max_iter=5000))])\n",
    "parameters4 = {'logreg__C': np.logspace(-8, 8, 17, base=2)} # defining parameter space\n",
    "clf4 = GridSearchCV(pipe, parameters4, cv=3)\n",
    "clf4.fit(X_train, y_train)\n",
    "\n",
    "print('Returned hyperparameter: {}'.format(clf4.best_params_))\n",
    "print('Best classification accuracy in train is: {}'.format(clf4.best_score_))\n",
    "print('Classification accuracy on test is: {}'.format(clf4.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** what is the difference between ```StandardScaler()``` and ```MaxAbsScaler()```? What are other scaling options available in ```sklearn```?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** using the previous code as an example achieve test accuracy $\\geq 0.9$. You can use any method from sklearn package. Give a mathematical description of the selected method. Explain the range of considered hyperparamers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some ```sklearn``` methods are able to output probabilities ```predict_proba(X_test)```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** There is a mistake in the following chunk of code. Fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "axes = plt.subplots(2, 4)[1]  # creates a grid of 10 plots\n",
    "\n",
    "# More details about zip() function here https://docs.python.org/3.3/library/functions.html#zip\n",
    "y_pred = clf4.predict(X_test)\n",
    "j = 0 # Index which iterates over plots\n",
    "for true_label, pred_label, image in list(zip(y_test, y_pred, X_test)):\n",
    "    if j == 4: # We only want to look at 4 first mistakes\n",
    "        break\n",
    "    if true_label != pred_label:\n",
    "        # Plotting predicted probabilities\n",
    "        axes[1, j].bar(np.arange(10), clf4.predict_proba(image.reshape(1, -1))) \n",
    "        axes[1, j].set_xticks(np.arange(10))\n",
    "        axes[1, j].set_yticks([])\n",
    "        \n",
    "        # Plotting the image\n",
    "        axes[0, j].imshow(image.reshape((28, 28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        axes[0, j].set_xticks([])\n",
    "        axes[0, j].set_yticks([])\n",
    "        axes[0, j].set_title('Predicted {}'.format(pred_label))\n",
    "        j += 1\n",
    "        \n",
    "#         plt.xticks(x, ('Bill', 'Fred', 'Mary', 'Sue'))\n",
    "#         axex[1, j].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing the Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It often happens that the accuracy is not the right way to evaluate the performance. ```sklearn``` has a large variety of other metrics both in classification and regression. See https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "\n",
    "Here we want to understand how to change the cross-validation metric with minimal effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVM Classifier + Pipeline + New score function\n",
    "\n",
    "pipe = Pipeline([('scaler', MaxAbsScaler()), ('svc', svc)])\n",
    "parameters4 = {'svc__C': np.logspace(-8, 8, 17, base=2)} # defining parameter space\n",
    "balanced_scorer = make_scorer(balanced_accuracy_score)\n",
    "\n",
    "clf4 = GridSearchCV(pipe, parameters3, cv=3, scoring=balanced_scorer)\n",
    "clf4.fit(X_train, y_train)\n",
    "\n",
    "print('Returned hyperparameter: {}'.format(clf4.best_params_))\n",
    "print('Best Balanced accuracy in train is: {}'.format(clf4.best_score_))\n",
    "print('Balanced accuracy on test is: {}'.format(clf4.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is ```balanced_accuracy_score```? Write its mathematical mathematical description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Sometimes it is important to look at the confusion matrix of the prediction.\n",
    "\n",
    "**Question:** What is the confusion matrix? What are the conclusions that we can draw from the ```confusion_matrix(y_test, clf4.predict(X_test))```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, clf4.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2 -- Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that we have contains images with $10$ classes. Normally, accuracy is a reasonable choice of the loss function to be optimized, but in this problem we *really* do not like when digits from $\\{5, 6, 7, 8, 9\\}$ are predicted to be from $\\{0, 1, 2, 3, 4\\}$.\n",
    "\n",
    "**Question:** Propose a loss function that would address our needs. Explain your choice.\n",
    "\n",
    "**Question:** Following above examples, make an ML pipeline that uses *your* loss function and finds appropriate classifiers.\n",
    "\n",
    "When writing your report on this part, include:\n",
    "   1. description of your loss function\n",
    "   2. description of the pipeline\n",
    "   3. description of the algorithms that you used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
